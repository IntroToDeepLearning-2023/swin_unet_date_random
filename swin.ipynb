{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Diane10/ethicsdataset/blob/main/IDL_Gustave.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install visdom==0.1.7 wandb rasterio\n",
        "!pip install einops\n",
        "!pip install einsum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUYOcElVgJTk",
        "outputId": "b3e43135-8688-4fc4-aa2f-fab0e10842e2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: visdom==0.1.7 in /usr/local/lib/python3.10/dist-packages (0.1.7)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.10/dist-packages (1.3.9)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.10/dist-packages (from visdom==0.1.7) (1.23.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from visdom==0.1.7) (9.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from visdom==0.1.7) (2.31.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from visdom==0.1.7) (6.3.2)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from visdom==0.1.7) (23.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from visdom==0.1.7) (1.16.0)\n",
            "Requirement already satisfied: torchfile in /usr/local/lib/python3.10/dist-packages (from visdom==0.1.7) (0.1.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.40)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.35.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.10/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2023.7.22)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.4.7)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->visdom==0.1.7) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->visdom==0.1.7) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->visdom==0.1.7) (2.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: einsum in /usr/local/lib/python3.10/dist-packages (0.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NSIfpgc-esut"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional\n",
        "import torch.nn.functional as F\n",
        "from torch import autograd\n",
        "import torch.optim as optim\n",
        "\n",
        "import os\n",
        "from glob import glob\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from matplotlib import pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "\n",
        "import visdom\n",
        "from torchvision.utils import save_image, make_grid\n",
        "import datetime\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "import wandb\n",
        "import math\n",
        "from einops import rearrange\n",
        "\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "from datetime import datetime\n",
        "import rasterio\n",
        "from pathlib import Path\n",
        "\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.utils.rnn as rnn\n",
        "import json\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import WeightedRandomSampler, SubsetRandomSampler\n",
        "from torchvision import models\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3dU0Zi89g1j",
        "outputId": "3874246f-0e4a-4cc4-e737-046094bfaa41"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !gsutil ls gs://data_ctm/data/data/africa_crop_type_mapping/ghana/"
      ],
      "metadata": {
        "id": "Wbh4v4pEl5T2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pd.read_csv('gs://data_ctm/data/data/africa_crop_type_mapping/ghana/.ipynb_checkpoints/list_eval_partition-checkpoint.csv')"
      ],
      "metadata": {
        "id": "SY-paNovb01w"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BAND STATS\n",
        "\n",
        "BANDS = { 's1': { 'VV': 0, 'VH': 1, 'RATIO': 2},\n",
        "          's2': { '10': {'BLUE': 0, 'GREEN': 1, 'RED': 2, 'RDED1': 3, 'RDED2': 4, 'RDED3': 5, 'NIR': 6, 'RDED4': 7, 'SWIR1': 8, 'SWIR2': 9},\n",
        "                   '4': {'BLUE': 0, 'GREEN': 1, 'RED': 2, 'NIR': 3}},\n",
        "          'planet': { '4': {'BLUE': 0, 'GREEN': 1, 'RED': 2, 'NIR': 3}}}\n",
        "\n",
        "MEANS = { 's1': { 'ghana': torch.Tensor([-10.50, -17.24, 1.17]),\n",
        "                  'southsudan': torch.Tensor([-9.02, -15.26, 1.15])},\n",
        "          's2': { 'ghana': torch.Tensor([2620.00, 2519.89, 2630.31, 2739.81, 3225.22, 3562.64, 3356.57, 3788.05, 2915.40, 2102.65]),\n",
        "                  'southsudan': torch.Tensor([2119.15, 2061.95, 2127.71, 2277.60, 2784.21, 3088.40, 2939.33, 3308.03, 2597.14, 1834.81])},\n",
        "          'planet': { 'ghana': torch.Tensor([1264.81, 1255.25, 1271.10, 2033.22]),\n",
        "                      'southsudan': torch.Tensor([1091.30, 1092.23, 1029.28, 2137.77])},\n",
        "          's2_cldfltr': { 'ghana': torch.Tensor([1362.68, 1317.62, 1410.74, 1580.05, 2066.06, 2373.60, 2254.70, 2629.11, 2597.50, 1818.43]),\n",
        "                  'southsudan': torch.Tensor([1137.58, 1127.62, 1173.28, 1341.70, 1877.70, 2180.27, 2072.11, 2427.68, 2308.98, 1544.26])} }\n",
        "\n",
        "STDS = { 's1': { 'ghana': torch.Tensor([3.57, 4.86, 5.60]),\n",
        "                 'southsudan': torch.Tensor([4.49, 6.68, 21.75])},\n",
        "         's2': { 'ghana': torch.Tensor([2171.62, 2085.69, 2174.37, 2084.56, 2058.97, 2117.31, 1988.70, 2099.78, 1209.48, 918.19]),\n",
        "                 'southsudan': torch.Tensor([2113.41, 2026.64, 2126.10, 2093.35, 2066.81, 2114.85, 2049.70, 2111.51, 1320.97, 1029.58])},\n",
        "         'planet': { 'ghana': torch.Tensor([602.51, 598.66, 637.06, 966.27]),\n",
        "                     'southsudan': torch.Tensor([526.06, 517.05, 543.74, 1022.14])},\n",
        "         's2_cldfltr': { 'ghana': torch.Tensor([511.19, 495.87, 591.44, 590.27, 745.81, 882.05, 811.14, 959.09, 964.64, 809.53]),\n",
        "                 'southsudan': torch.Tensor([548.64, 547.45, 660.28, 677.55, 896.28, 1066.91, 1006.01, 1173.19, 1167.74, 865.42])} }\n",
        "\n",
        "\n",
        "CROPS = { 'ghana': ['groundnut', 'maize', 'rice', 'soya bean'],\n",
        "          'southsudan': ['sorghum', 'maize', 'rice', 'groundnut']}"
      ],
      "metadata": {
        "id": "1YOZuJC1SXNw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CropTypeMappingDataset():\n",
        "\n",
        "    def __init__(self, ):\n",
        "\n",
        "        self.data_dir = '/content/data/africa_crop_type_mapping' # 'gs://data_ctm/data/africa_crop_type_mapping'\n",
        "\n",
        "        self.split_dict = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.split_names = {'train': 'Train', 'val': 'Validation', 'test': 'Test'}\n",
        "\n",
        "        # Extract splits\n",
        "        split_df = pd.read_csv(os.path.join(self.data_dir, 'ghana', 'list_eval_partition.csv'))\n",
        "\n",
        "        self.split_array = split_df['partition'].values\n",
        "\n",
        "\n",
        "        # y_array stores idx ids corresponding to location. Actual y labels are\n",
        "        # tensors that are loaded separately.\n",
        "        self.y_array = torch.from_numpy(split_df['id'].values)\n",
        "\n",
        "        self.y_size = (64, 64)\n",
        "\n",
        "        self.metadata_fields = ['y']\n",
        "        self.metadata_array = torch.from_numpy(split_df['id'].values)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Any transformations are handled by the SustainBenchSubset\n",
        "        # since different subsets (e.g., train vs test) might have different transforms\n",
        "        x = self.get_input(idx)\n",
        "        y = self.get_label(idx)\n",
        "        return x, y\n",
        "\n",
        "\n",
        "    def get_input(self, idx):\n",
        "        \"\"\"\n",
        "        Returns X for a given idx.\n",
        "        \"\"\"\n",
        "        loc_id = f'{self.y_array[idx]:06d}'\n",
        "\n",
        "        images = np.load(os.path.join(self.data_dir, 'ghana', 'npy', f'{\"ghana\"}_{loc_id}.npz'))\n",
        "        dates_idx = self.get_dates(loc_id)\n",
        "\n",
        "        s1 = images['s1']\n",
        "        s2 = images['s2']\n",
        "        planet = images['planet']\n",
        "\n",
        "        s1 = torch.from_numpy(s1)\n",
        "        s2 = torch.from_numpy(s2.astype(np.int32))\n",
        "        planet = torch.from_numpy(planet.astype(np.int32))\n",
        "\n",
        "        planet = planet.permute(3, 0, 1, 2)\n",
        "        planet = transforms.CenterCrop(128)(planet)\n",
        "        planet = planet.permute(1, 2, 3, 0)\n",
        "\n",
        "        # Normalization\n",
        "        s1 = self.normalization(s1, 's1')\n",
        "        s2 = self.normalization(s2, 's2')\n",
        "        planet = self.normalization(planet, 'planet')\n",
        "\n",
        "        s1 = s1[:,:,:,dates_idx[\"s1_min\"]:dates_idx[\"s1_max\"]]\n",
        "        s2 = s2[:,:,:,dates_idx[\"s2_min\"]:dates_idx[\"s2_max\"]]\n",
        "        planet = planet[:,:,:,dates_idx[\"planet_min\"]:dates_idx[\"planet_max\"]]\n",
        "\n",
        "        s1_d = random.randint(0, dates_idx[\"s1_max\"] - dates_idx[\"s1_min\"]-1)\n",
        "        s2_d = random.randint(0, dates_idx[\"s2_max\"] - dates_idx[\"s2_min\"]-1)\n",
        "        planet_d = random.randint(0, dates_idx[\"planet_max\"] - dates_idx[\"planet_min\"]-1)\n",
        "\n",
        "        s1 = np.squeeze(s1[:,:,:,s1_d])\n",
        "        s2 = np.squeeze(s2[:,:,:,s2_d])\n",
        "        planet = np.squeeze(planet[:,:,:,planet_d])\n",
        "\n",
        "\n",
        "        return {'s1': torch.tensor(s1, dtype=torch.float32), 's2': torch.tensor(s2, dtype=torch.float32), 'planet': torch.tensor(planet, dtype=torch.float32)}\n",
        "\n",
        "    def get_label(self, idx):\n",
        "        \"\"\"\n",
        "        Returns y for a given idx.\n",
        "        \"\"\"\n",
        "        loc_id = f'{self.y_array[idx]:06d}'\n",
        "        label = np.load(os.path.join(self.data_dir, 'ghana', 'truth', f'{\"ghana\"}_{loc_id}.npz'))['truth']\n",
        "        label = torch.from_numpy(label)\n",
        "        label[label>4]=0\n",
        "        return label\n",
        "\n",
        "    def get_dates(self, loc_id):\n",
        "        \"\"\"\n",
        "        Converts json dates into tensor containing dates\n",
        "        \"\"\"\n",
        "        s1_json = json.loads(open(os.path.join(self.data_dir, 'ghana', 's1', f\"s1_{'ghana'}_{loc_id}.json\"), 'r').read())\n",
        "        s1 = s1_json['dates']\n",
        "\n",
        "        s1 =np.array([datetime.strptime(date, \"%Y-%m-%d\") for date in s1])\n",
        "        s1_date_low = s1[s1 >= datetime.strptime('2016-06-01', \"%Y-%m-%d\")]\n",
        "        s1_date_high = s1_date_low[s1_date_low<= datetime.strptime('2016-11-30', \"%Y-%m-%d\")]\n",
        "        s1_idx_min = np.where(s1==s1_date_high[0])\n",
        "        s1_idx_max = np.where(s1==s1_date_high[-1])\n",
        "        s1_idx_min = s1_idx_min[0][0]\n",
        "        s1_idx_max = s1_idx_max[0][0]\n",
        "\n",
        "\n",
        "        s2_json = json.loads(open(os.path.join(self.data_dir, 'ghana', 's2', f\"s2_{'ghana'}_{loc_id}.json\"), 'r').read())\n",
        "        s2 = s2_json['dates']\n",
        "\n",
        "        s2 =np.array([datetime.strptime(date, \"%Y-%m-%d\") for date in s2])\n",
        "        s2_date_low = s2[s2 >= datetime.strptime('2016-07-01', \"%Y-%m-%d\")]\n",
        "        s2_date_high = s2_date_low[s2_date_low<= datetime.strptime('2016-11-30', \"%Y-%m-%d\")]\n",
        "        s2_idx_min = np.where(s2==s2_date_high[0])\n",
        "        s2_idx_max = np.where(s2==s2_date_high[-1])\n",
        "        s2_idx_min = s2_idx_min[0][0]\n",
        "        s2_idx_max = s2_idx_max[0][0]\n",
        "\n",
        "        planet_json = json.loads(open(os.path.join(self.data_dir, 'ghana', 'planet', f\"planet_{'ghana'}_{loc_id}.json\"), 'r').read())\n",
        "        planet = planet_json['dates']\n",
        "\n",
        "        planet =np.array([datetime.strptime(date, \"%Y-%m-%d\") for date in planet])\n",
        "        planet_date_low = planet[planet >= datetime.strptime('2017-07-01', \"%Y-%m-%d\")]\n",
        "        planet_date_high = planet_date_low[planet_date_low<= datetime.strptime('2017-11-30', \"%Y-%m-%d\")]\n",
        "        planet_idx_min = np.where(planet==planet_date_high[0])\n",
        "        planet_idx_max = np.where(planet==planet_date_high[-1])\n",
        "        planet_idx_min = planet_idx_min[0][0]\n",
        "        planet_idx_max = planet_idx_max[0][0]\n",
        "\n",
        "        return {\"s1_min\":s1_idx_min, \"s1_max\":s1_idx_max, \"s2_min\":s2_idx_min,\"s2_max\":s2_idx_max,\"planet_min\":planet_idx_min,\"planet_max\":planet_idx_max}\n",
        "\n",
        "    def normalization(self, grid, satellite):\n",
        "        \"\"\" Normalization based on values defined in constants.py\n",
        "        Args:\n",
        "          grid - (tensor) grid to be normalized\n",
        "          satellite - (str) describes source that grid is from (\"s1\" or \"s2\")\n",
        "        Returns:\n",
        "          grid - (tensor) a normalized version of the input grid\n",
        "        \"\"\"\n",
        "        num_bands = grid.shape[0]\n",
        "        means = MEANS[satellite]['ghana']\n",
        "        stds = STDS[satellite]['ghana']\n",
        "        grid = (grid-means[:num_bands].reshape(num_bands, 1, 1, 1))/stds[:num_bands].reshape(num_bands, 1, 1, 1)\n",
        "\n",
        "        if satellite not in ['s1', 's2', 'planet']:\n",
        "            raise ValueError(\"Incorrect normalization parameters\")\n",
        "        return grid"
      ],
      "metadata": {
        "id": "ptixpERuqUjn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SustainBenchSubset(CropTypeMappingDataset):\n",
        "    def __init__(self, dataset, split, transform=None):\n",
        "        \"\"\"\n",
        "        This acts like torch.utils.data.Subset, but on SustainBenchDatasets.\n",
        "        We pass in transform explicitly because it can potentially vary at\n",
        "        training vs. test time, if we're using data augmentation.\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "        split_mask = self.split_array == self.split_dict[split]\n",
        "        self.indices = np.where(split_mask)[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.dataset[self.indices[idx]]\n",
        "        if self.transform is not None:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)"
      ],
      "metadata": {
        "id": "cYQ28yM-Uh1U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CropTypeMappingDataset()\n",
        "\n",
        "train_dataset = SustainBenchSubset(dataset, 'train')\n",
        "val_dataset = SustainBenchSubset(dataset, 'val')\n"
      ],
      "metadata": {
        "id": "Ne5kcG3f504w"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "                train_dataset,\n",
        "                shuffle=True, # Shuffle training dataset\n",
        "                sampler=None,\n",
        "                batch_size=10)\n",
        "\n",
        "val_loader = DataLoader(\n",
        "                val_dataset,\n",
        "                shuffle=False, # Do not shuffle eval datasets\n",
        "                sampler=None,\n",
        "                batch_size=10)"
      ],
      "metadata": {
        "id": "Z-LJe67O2ese"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in train_loader:\n",
        "  print(x['planet'].shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1At28FaU4MwI",
        "outputId": "0dba962a-5e4f-49ee-b239-ae9e965f3070"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 4, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model"
      ],
      "metadata": {
        "id": "AlRsC3QCvWXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class cyclicShift(nn.Module):\n",
        "  def __init__(self, displacement):\n",
        "    super().__init__()\n",
        "    self.displacement = displacement\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.roll(x, shifts=(self.displacement, self.displacement), dims = (1,2) )\n",
        "\n",
        "\n",
        "class Residual(nn.Module):\n",
        "  def __init__(self, fn):\n",
        "    super().__init__()\n",
        "    self.fn = fn\n",
        "\n",
        "  def forward(self, x, **kwargs):\n",
        "    return self.fn(x,**kwargs) + x\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "  def __init__(self, dim, fn):\n",
        "    super().__init__()\n",
        "    self.norm = nn.LayerNorm(dim)\n",
        "    self.fn = fn\n",
        "\n",
        "  def forward(self, x, **kwargs):\n",
        "    return self.norm(self.fn(x, **kwargs))\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self,dim,hidden_dim):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(dim, hidden_dim),\n",
        "        nn.GELU(),\n",
        "        nn.Linear(hidden_dim, dim)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "ra0-6NNI4HfJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mask(window_size, displacement, upper_lower,left_right):\n",
        "  mask = torch.zeros(window_size**2, window_size**2)\n",
        "\n",
        "  if upper_lower:\n",
        "    mask[-displacement*window_size:,:-displacement*window_size]=float(\"-inf\")\n",
        "    mask[:-displacement*window_size,-displacement*window_size:]=float(\"-inf\")\n",
        "\n",
        "  if left_right:\n",
        "    mask = rearrange(mask, \"(h1 w1) (h2 w2) -> h1 w1 h2 w2\", h1=window_size,h2=window_size)\n",
        "    mask[:,-displacement:, :, :-displacement] = float(\"-inf\")\n",
        "    mask[:,:-displacement, :,-displacement:] = float(\"-inf\")\n",
        "    mask = rearrange(mask, \"h1 w1 h2 w2 -> (h1 w1) (h2 w2)\")\n",
        "\n",
        "  return mask"
      ],
      "metadata": {
        "id": "nxD3n5lP4LQ5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WindowAttension(nn.Module):\n",
        "  def __init__(self, dim, heads, head_dim, shifted, window_size, relative_pos_embedding):\n",
        "    super().__init__()\n",
        "    inner_dim = head_dim * heads\n",
        "    self.heads = heads\n",
        "    self.scale = head_dim ** -0.5\n",
        "    self.window_size = window_size\n",
        "    self.relative_pos_embedding = relative_pos_embedding\n",
        "    self.shifted = shifted\n",
        "\n",
        "    if self.shifted:\n",
        "      displacement = window_size //2\n",
        "      self.cyclic_shift = cyclicShift(-displacement)\n",
        "      self.cyclic_back_shift = cyclicShift(displacement)\n",
        "\n",
        "      self.upper_lower_mask = nn.Parameter(create_mask(window_size=window_size, displacement=displacement,\\\n",
        "                                                       upper_lower=True, left_right=False), requires_grad=False)\n",
        "\n",
        "      self.left_right_mask = nn.Parameter(create_mask(window_size=window_size, displacement=displacement,\\\n",
        "                                                       upper_lower=False, left_right=True), requires_grad=False)\n",
        "\n",
        "    self.to_qkv = nn.Linear(dim, inner_dim*3,bias=False)\n",
        "    self.pos_embedding = nn.Parameter(torch.randn(window_size**2,window_size**2))\n",
        "    self.to_out = nn.Linear(inner_dim, dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    if self.shifted:\n",
        "      x = self.cyclic_shift(x)\n",
        "\n",
        "    b, n_h, n_w, _, h = *x.shape, self.heads\n",
        "    qkv = self.to_qkv(x).chunk(3,dim=-1)\n",
        "\n",
        "    nw_h = n_h // self.window_size\n",
        "    nw_w = n_w // self.window_size\n",
        "\n",
        "    q, k, v = map(lambda t: rearrange(t, \"b (nw_h w_h) (nw_w w_w) (h d)->b h (nw_h nw_w) (w_h w_w) d\",\\\n",
        "                                      h=h,w_h=self.window_size,w_w=self.window_size), qkv)\n",
        "    # Do product similarity\n",
        "    dots = torch.einsum(\"b h w i d, b h w j d->b h w i j\", q, k) * self.scale\n",
        "    dots +=self.pos_embedding\n",
        "    if self.shifted:\n",
        "      dots[:,:,-nw_w:] +=self.upper_lower_mask\n",
        "      dots[:,:,nw_w-1::nw_w] += self.left_right_mask\n",
        "\n",
        "    attn = dots.softmax(dim=-1)\n",
        "    out = torch.einsum(\"b h w i j, b h w j d->b h w i d\", attn, v)\n",
        "\n",
        "    out = rearrange(out, \"b h (nw_h nw_w) (w_h w_w) d -> b (nw_h w_h) (nw_w w_w) (h d)\",\\\n",
        "                    h=h, w_h=self.window_size, w_w=self.window_size, nw_h=nw_h, nw_w=nw_w)\n",
        "\n",
        "    out = self.to_out(out)\n",
        "    if self.shifted:\n",
        "       out = self.cyclic_back_shift(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "MEgIDShi4LEg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SwinBlock(nn.Module):\n",
        "  def __init__(self, dim, heads, head_dim, mlp_dim, shifted, window_size, relative_pos_embedding) :\n",
        "    super().__init__()\n",
        "    self.attention_block = Residual(PreNorm(dim, WindowAttension(dim=dim,heads=heads,head_dim=head_dim,\\\n",
        "                                                                 shifted=shifted, window_size=window_size,\\\n",
        "                                                                 relative_pos_embedding=relative_pos_embedding)))\n",
        "\n",
        "    self.mlp_block = Residual(PreNorm(dim, FeedForward(dim=dim,hidden_dim=mlp_dim)))\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.attention_block(x)\n",
        "    x = self.mlp_block(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "GxT0Gxxa4UkJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchExpanding(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1):\n",
        "    super().__init__()\n",
        "    self.patch_expand = nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
        "                                           stride=stride, padding=padding, output_padding=output_padding)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.patch_expand(x).permute(0,2,3,1)\n",
        "    return x\n",
        "\n",
        "class PatchMerging_Conv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, downscaling_factor):\n",
        "    super().__init__()\n",
        "    self.patch_merge = nn.Conv2d(in_channels, out_channels, kernel_size=downscaling_factor,stride=downscaling_factor,padding=0)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.patch_merge(x).permute(0,2,3,1)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Gf2bOGEH4UgI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StageModule(nn.Module):\n",
        "  def __init__(self,in_channels, hidden_dimension, layers, scaling_factor,num_heads,head_dim, window_size, relative_pos_embedding,\n",
        "               PatchMerging=True, stride=2, padding=1, output_padding=1):\n",
        "    super().__init__()\n",
        "    assert layers % 2 == 0, \"Stage layers need to be divisible by 2 for regular and shftrd block\"\n",
        "    if PatchMerging:\n",
        "      self.patch_partition = PatchMerging_Conv(in_channels=in_channels, out_channels=hidden_dimension,downscaling_factor=scaling_factor)\n",
        "    else:\n",
        "      self.patch_partition = PatchExpanding(in_channels=in_channels , out_channels=hidden_dimension, kernel_size=scaling_factor, stride=stride,\n",
        "                                            padding=padding, output_padding=output_padding)\n",
        "\n",
        "    self.layers = nn.ModuleList([])\n",
        "    for _ in range(layers//2):\n",
        "      self.layers.append(nn.ModuleList([\n",
        "          SwinBlock(dim=hidden_dimension,heads=num_heads, head_dim = head_dim, mlp_dim=hidden_dimension *4, shifted =False,\\\n",
        "                    window_size = window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "\n",
        "          SwinBlock(dim=hidden_dimension,heads=num_heads, head_dim = head_dim, mlp_dim=hidden_dimension *4, shifted =True,\\\n",
        "                    window_size = window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "      ]))\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.patch_partition(x)\n",
        "\n",
        "    for regular_block, shifted_block in self.layers:\n",
        "      x = regular_block (x)\n",
        "      x = shifted_block (x)\n",
        "    return x.permute(0,3,1,2)"
      ],
      "metadata": {
        "id": "8DN4HwDY4ZPM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SwinTransformerUnet(nn.Module):\n",
        "  def __init__(self,*,hidden_dim, layers, channels=3, num_classes=5, heads=(3,6,12,24), head_dim=32,window_size=7, \\\n",
        "               downscaling_factors=(4,2,2,2), scaling_factor=(3,3,3,4), relative_pos_embedding=True):\n",
        "    super().__init__()\n",
        "    # Encoder\n",
        "    self.stage1 = StageModule(in_channels=channels, hidden_dimension=hidden_dim,layers=layers[0],\\\n",
        "                              scaling_factor=downscaling_factors[0],num_heads=heads[0],head_dim=head_dim,\\\n",
        "                              window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "\n",
        "    self.stage2 = StageModule(in_channels=hidden_dim, hidden_dimension=hidden_dim*2,layers=layers[1],\\\n",
        "                              scaling_factor=downscaling_factors[1],num_heads=heads[1],head_dim=head_dim,\\\n",
        "                              window_size=window_size, relative_pos_embedding=relative_pos_embedding\n",
        "                              )\n",
        "    self.stage3 = StageModule(in_channels=hidden_dim*2, hidden_dimension=hidden_dim*4,layers=layers[2],\\\n",
        "                              scaling_factor=downscaling_factors[2],num_heads=heads[2],head_dim=head_dim,\\\n",
        "                              window_size=window_size, relative_pos_embedding=relative_pos_embedding\n",
        "                              )\n",
        "    self.stage4 = StageModule(in_channels=hidden_dim*4, hidden_dimension=hidden_dim*8,layers=layers[3],\\\n",
        "                              scaling_factor=downscaling_factors[3],num_heads=heads[3],head_dim=head_dim,\\\n",
        "                              window_size=window_size, relative_pos_embedding=relative_pos_embedding\n",
        "                              )\n",
        "\n",
        "    #Decoder\n",
        "    self.stage11 = StageModule(in_channels=hidden_dim*8, hidden_dimension=hidden_dim*4,layers=layers[0],\\\n",
        "                              scaling_factor=scaling_factor[0],num_heads=heads[3],head_dim=head_dim,\\\n",
        "                              window_size=window_size, PatchMerging=False, relative_pos_embedding=relative_pos_embedding)\n",
        "\n",
        "    self.stage22 = StageModule(in_channels=hidden_dim*4+hidden_dim*4, hidden_dimension=hidden_dim*2,layers=layers[1],\\\n",
        "                              scaling_factor=scaling_factor[1],num_heads=heads[2],head_dim=head_dim,\\\n",
        "                              window_size=window_size, PatchMerging=False, relative_pos_embedding=relative_pos_embedding\n",
        "                              )\n",
        "    self.stage33 = StageModule(in_channels=hidden_dim*2+hidden_dim*2, hidden_dimension=hidden_dim,layers=layers[2],\\\n",
        "                              scaling_factor=scaling_factor[2],num_heads=heads[1],head_dim=head_dim,\\\n",
        "                              window_size=window_size, PatchMerging=False, relative_pos_embedding=relative_pos_embedding\n",
        "                              )\n",
        "    self.stage44 = StageModule(in_channels=hidden_dim+hidden_dim, hidden_dimension=hidden_dim,layers=layers[3],\\\n",
        "                              scaling_factor=scaling_factor[3],num_heads=heads[0],head_dim=head_dim,\\\n",
        "                              stride=4, padding=1, output_padding=2, window_size=window_size, PatchMerging=False,\\\n",
        "                              relative_pos_embedding=relative_pos_embedding\n",
        "                              )\n",
        "\n",
        "  def forward(self, img):\n",
        "    #Encoder\n",
        "    stage1 = self.stage1(img)\n",
        "    stage2 = self.stage2(stage1)\n",
        "    stage3 = self.stage3(stage2)\n",
        "    stage4 = self.stage4(stage3)\n",
        "\n",
        "    #Decoder\n",
        "    x = self.stage11(stage4)\n",
        "    x=torch.cat([x, stage3], dim=1)\n",
        "    x = self.stage22(x)\n",
        "    x=torch.cat([x, stage2], dim=1)\n",
        "    x = self.stage33(x)\n",
        "    x=torch.cat([x, stage1], dim=1)\n",
        "    x = self.stage44(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "sMxeJAUV4ZMd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SwinUnet(nn.Module):\n",
        "  def __init__(self,):\n",
        "    super().__init__()\n",
        "    self.planet = SwinTransformerUnet(hidden_dim = 96, layers=(2,6,2,2),heads=(3,6,12,24),channels=4,num_classes=5,head_dim=32,\\\n",
        "             window_size=2,relative_pos_embedding=True)\n",
        "\n",
        "    self.final_planet = nn.Conv2d(in_channels=96, out_channels=96, stride= 2, kernel_size=2 ,padding= 0)\n",
        "\n",
        "    self.s1 = SwinTransformerUnet(hidden_dim = 96, layers=(2,6,2,2),heads=(3,6,12,24),channels=3,num_classes=5,head_dim=32,\\\n",
        "             window_size=2,relative_pos_embedding=True)\n",
        "\n",
        "    self.s2 = SwinTransformerUnet(hidden_dim = 96, layers=(2,6,2,2),heads=(3,6,12,24),channels=10,num_classes=5,head_dim=32,\\\n",
        "             window_size=2,relative_pos_embedding=True)\n",
        "\n",
        "    self.final=nn.Conv2d(in_channels=288, out_channels=5, kernel_size=3,\n",
        "                               stride=1, padding=1)\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "  def forward(self,X):\n",
        "\n",
        "\n",
        "    planet = self.final_planet(self.planet(X['planet'].to(DEVICE)))\n",
        "    s1 = self.s1(X['s1'].to(DEVICE))\n",
        "    s2 = self.s2(X['s2'].to(DEVICE))\n",
        "    out = self.final(torch.cat([s1, s2, planet], dim=1))\n",
        "    return self.softmax(out)"
      ],
      "metadata": {
        "id": "2_L4UnI_4ZEO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model object\n",
        "model_swin = SwinUnet().to(DEVICE)\n"
      ],
      "metadata": {
        "id": "YflCiStTqz1p"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_weights = 1 - np.array([.85, .17, .56, .16, .11])\n",
        "loss_weights = torch.tensor(loss_weights, dtype=torch.float32).cuda()\n",
        "\n",
        "config = {\n",
        "    \"epochs\"           : 100,\n",
        "    \"lr\"               : 0.001,\n",
        "    \"label_smoothing\"  : 0.2,\n",
        "    \"momentum\"         : 0.9,\n",
        "    \"weight_decay\"     : 0.0001,\n",
        "    \"loss_weights\"     : loss_weights\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "QQMrjeTmrDjJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMFZ5Q3UesvA"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wki28zN9esvA",
        "outputId": "cd58ddc1-15da-42c0-be21-4dffeeb58462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbwirayesu\u001b[0m (\u001b[33mwn\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "wandb.login(key=\"ed120be65ed3b503c10399eb93a51f7112e342dc\") #API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "2USolO4MesvB",
        "outputId": "9a661bb4-0441-476a-9eba-e8474c730669"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "wandb version 0.16.1 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231206_105936-u4ujzh2v</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/wn/Crop-type-segmentation/runs/u4ujzh2v' target=\"_blank\">SwinT-Ghana-indivTime-1</a></strong> to <a href='https://wandb.ai/wn/Crop-type-segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/wn/Crop-type-segmentation' target=\"_blank\">https://wandb.ai/wn/Crop-type-segmentation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/wn/Crop-type-segmentation/runs/u4ujzh2v' target=\"_blank\">https://wandb.ai/wn/Crop-type-segmentation/runs/u4ujzh2v</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "run = wandb.init(\n",
        "    name = \"SwinT-Ghana-indivTime-1\", ## Wandb creates random run names if you skip this field\n",
        "    # reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
        "    id ='u4ujzh2v', ### Insert specific run id here if you want to resume a previous run\n",
        "    resume = \"must\", ### You need this to resume previous runs, but comment out reinit = True when using this\n",
        "    project = \"Crop-type-segmentation\", ### Project should be created in your wandb account\n",
        "     ### Wandb Config for your run\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSyt3BWE9RzM",
        "outputId": "322b53c7-0b1e-4cce-b23a-4dd5a95b45b0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6717"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# metrics, train and validation functions\n",
        "def reshapeForLoss(y):\n",
        "    \"\"\" Reshapes labels or preds for loss fn.\n",
        "    To get them to the correct shape, we permute:\n",
        "      [batch x classes x rows x cols] --> [batch x rows x cols x classes]\n",
        "      and then reshape to [N x classes], where N = batch*rows*cols\n",
        "    \"\"\"\n",
        "    # [batch x classes x rows x cols] --> [batch x rows x cols x classes]\n",
        "    y = y.permute(0, 2, 3, 1)\n",
        "    # [batch x rows x cols x classes] --> [batch*rows*cols x classes]\n",
        "    y = y.contiguous().view(-1, y.shape[3])\n",
        "    return y"
      ],
      "metadata": {
        "id": "WdzAvndyp9RJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FugQI96hjnmz"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_ce_loss(y_true, y_pred, weight_scale=1):\n",
        "\n",
        "    y_true = reshapeForLoss(y_true)\n",
        "    num_examples = torch.sum(y_true, dtype=torch.float32).cuda()\n",
        "    y_pred = reshapeForLoss(y_pred)\n",
        "\n",
        "    loss_mask = torch.sum(y_true, dim=1).type(torch.LongTensor)\n",
        "    loss_mask_repeat = loss_mask.unsqueeze(1).repeat(1,y_pred.shape[1]).type(torch.FloatTensor)\n",
        "    _, y_true = torch.max(y_true, dim=1)\n",
        "    y_true = y_true * loss_mask\n",
        "    y_pred_ = y_pred * loss_mask_repeat.cuda()\n",
        "\n",
        "\n",
        "    loss_fn = nn.NLLLoss(weight = config[\"loss_weights\"] ** weight_scale)\n",
        "\n",
        "    total_loss = torch.sum(loss_fn(y_pred, y_true.cuda()))\n",
        "\n",
        "    if num_examples == 0:\n",
        "        print(\"WARNING: NUMBER OF EXAMPLES IS 0\")\n",
        "\n",
        "    else: return total_loss / num_examples"
      ],
      "metadata": {
        "id": "km57aBesQCrG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=config[\"label_smoothing\"], weight=config[\"loss_weights\"])\n",
        "optimizer = torch.optim.SGD(model_swin.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"], weight_decay=config[\"weight_decay\"])\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=0.00005)\n"
      ],
      "metadata": {
        "id": "upjuupIuUVjW"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Metrics\n",
        "def crop_segmentation_metrics(y_true, y_pred):\n",
        "        y_true = reshapeForLoss(y_true.cpu())\n",
        "        y_pred = reshapeForLoss(y_pred.cpu())\n",
        "\n",
        "        loss_mask = torch.sum(y_true, dim=1).type(torch.LongTensor)\n",
        "\n",
        "        _, y_true = torch.max(y_true, dim=1)\n",
        "        _, y_pred = torch.max(y_pred, dim=1)\n",
        "\n",
        "        y_true = y_true[loss_mask == 1]\n",
        "        y_pred = y_pred[loss_mask == 1]\n",
        "\n",
        "        assert (y_true.shape == y_pred.shape)\n",
        "        y_true = y_true.int()\n",
        "        y_pred = y_pred.int()\n",
        "        f1 = f1_score(y_true, y_pred, average='macro')\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "        return f1, acc, cm\n",
        "\n",
        "# Train\n",
        "def train_step(data_loader, optimizer, accuracy_fn):\n",
        "  \"\"\"Performs a training with model trying to learn on data-loader\"\"\"\n",
        "\n",
        "  curr_lr = float(optimizer.param_groups[0]['lr'])\n",
        "  model_swin.train() # Put model into training mode\n",
        "\n",
        "  train_loss, train_acc, train_f1=0,0,0\n",
        "  # Add a loop to loop through the training batches\n",
        "  for img,label in tqdm(data_loader):\n",
        "\n",
        "    # 1. Forwad pass\n",
        "    y_pred=model_swin(img)\n",
        "\n",
        "    # 2. Calculate loss and accuracy (per batch)\n",
        "    label = label.long()\n",
        "    label = torch.nn.functional.one_hot(label, num_classes=5).permute([0,3,1,2])\n",
        "    # label = label.to(DEVICE)\n",
        "\n",
        "\n",
        "    loss=mask_ce_loss(label, y_pred)\n",
        "\n",
        "    train_loss+=loss.item() #  accumulate training loss\n",
        "    # y_pred_masked = torch.max(y_pred,dim=1)[1]\n",
        "    train_acc += accuracy_fn(y_true=label, y_pred=y_pred)[1]\n",
        "    train_f1+=accuracy_fn(y_true=label, y_pred=y_pred)[0]\n",
        "\n",
        "    # print(torch.isnan(img['s1']).sum())\n",
        "    # print(torch.isnan(img['s2']).sum())\n",
        "    # print(torch.isnan(img['planet']).sum())\n",
        "    # print(loss.item())\n",
        "\n",
        "    # 3. optimize zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  # Divide total train loss and acc by lenth of train dataloader\n",
        "  train_loss/=len(data_loader)\n",
        "  train_acc/=len(data_loader)\n",
        "  train_f1/=len(data_loader)\n",
        "  print(f\"Train loss {train_loss: .5f}|Train acc : {train_acc:.4f} | Train f1: {train_f1:.4f} | lr: {curr_lr}\\n\")\n",
        "  return train_loss, train_acc, train_f1, curr_lr\n",
        "\n",
        "# Validation\n",
        "def validation_step(data_loader, accuracy_fn):\n",
        "  \"\"\"Performs a tesing loop step on model going over data loader.\"\"\"\n",
        "\n",
        "  val_loss,val_acc, val_f1=0,0,0\n",
        "\n",
        "  model_swin.eval() # put the model in eval mode\n",
        "  # turn on inference mode context manager\n",
        "  with torch.inference_mode():\n",
        "    for img,label in tqdm(data_loader):\n",
        "\n",
        "        # 1. Forward pass (outputs raw logits)\n",
        "      val_pred=model_swin(img)\n",
        "\n",
        "      # 2. Calculate the loss/acc\n",
        "      label = label.long()\n",
        "      label = torch.nn.functional.one_hot(label, num_classes=5).permute([0,3,1,2])\n",
        "      # label = label.to(DEVICE)\n",
        "      val_loss+=mask_ce_loss(label, val_pred)\n",
        "\n",
        "      # val_pred_masked = torch.max(val_pred,dim=1)[1]\n",
        "      val_acc += accuracy_fn(y_true=label, y_pred=val_pred)[1]\n",
        "      val_f1+=accuracy_fn(y_true=label, y_pred=val_pred)[0]\n",
        "\n",
        "    # Adjust metrics and print out\n",
        "    val_loss/=len(data_loader)\n",
        "    val_acc/=len(data_loader)\n",
        "    val_f1/=len(data_loader)\n",
        "    print(f\"Val loss: {val_loss:.5f} | Val acc: {val_acc:.4f} | Val f1: {val_f1:.4f}\\n\")\n",
        "\n",
        "    return val_loss, val_acc, val_f1"
      ],
      "metadata": {
        "id": "rMU5b1M6sq5x"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's train\n",
        "epochs=config['epochs']\n",
        "\n",
        "# Create an optimization and evluation using train_step() and val_step()\n",
        "train_loss_list=[]\n",
        "train_acc_list=[]\n",
        "train_f1_list=[]\n",
        "\n",
        "val_loss_list=[]\n",
        "val_acc_list=[]\n",
        "val_f1_list=[]\n",
        "\n",
        "\n",
        "best_val_f1 = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  print(f\"Epoch: {epoch}/{epochs} \\n----------------\")\n",
        "\n",
        "\n",
        "  train_loss, train_acc, train_f1, curr_lr = train_step(\n",
        "                                                data_loader=train_loader,\n",
        "                                                optimizer=optimizer,\n",
        "                                                accuracy_fn=crop_segmentation_metrics\n",
        "                                                )\n",
        "  train_loss_list.append(train_loss)\n",
        "  train_acc_list.append(train_acc)\n",
        "  train_f1_list.append(train_f1)\n",
        "\n",
        "  val_loss, val_acc, val_f1 = validation_step(\n",
        "                                            data_loader=val_loader,\n",
        "                                            accuracy_fn=crop_segmentation_metrics,\n",
        "                                            )\n",
        "  val_loss_list.append(val_loss)\n",
        "  val_acc_list.append(val_acc)\n",
        "  val_f1_list.append(val_f1)\n",
        "\n",
        "  wandb.log({\"train_loss\": train_loss, 'train_f1': train_f1, 'train_acc': train_acc, 'validation_f1':val_f1,\n",
        "               'validation_loss': val_loss, 'validation_acc': val_acc, \"learning_Rate\": curr_lr})\n",
        "\n",
        "  if val_f1 < best_val_f1:\n",
        "      best_val_loss = val_f1\n",
        "      torch.save(model_swin.state_dict(), './models/best.pth')  # Save the best model\n",
        "\n",
        "      print(\"Saving model\")\n",
        "      torch.save({'model_state_dict':model_swin.state_dict(),\n",
        "                'optimizer_state_dict':optimizer.state_dict(),\n",
        "                'scheduler_state_dict':scheduler.state_dict(),\n",
        "                'best_val_loss': best_val_loss,\n",
        "                'epoch': epoch}, './models/best.pth')\n",
        "\n",
        "      wandb.save('./models/best.pth')\n",
        "\n",
        "  scheduler.step()\n",
        "\n",
        "run.finish()\n"
      ],
      "metadata": {
        "id": "ue9jxHh94Ism",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a49218b-4579-4f5f-daf6-25792bbd2f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/100 \n",
            "----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 226/226 [21:31<00:00,  5.72s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss  0.00004|Train acc : 0.23 | Train f1: 0.09 | lr: 0.001\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 30/30 [02:46<00:00,  5.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.00004 | Val acc: 0.26 | Val f1: 0.10\n",
            "\n",
            "Saving model\n",
            "Epoch: 1/100 \n",
            "----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 226/226 [21:08<00:00,  5.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss  0.00004|Train acc : 0.29 | Train f1: 0.11 | lr: 0.0009997656161737224\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 30/30 [02:45<00:00,  5.51s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.00004 | Val acc: 0.32 | Val f1: 0.11\n",
            "\n",
            "Saving model\n",
            "Epoch: 2/100 \n",
            "----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 226/226 [21:04<00:00,  5.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss  0.00004|Train acc : 0.35 | Train f1: 0.12 | lr: 0.000999062696003429\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 30/30 [02:45<00:00,  5.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.00004 | Val acc: 0.38 | Val f1: 0.13\n",
            "\n",
            "Saving model\n",
            "Epoch: 3/100 \n",
            "----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 226/226 [21:10<00:00,  5.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss  0.00004|Train acc : 0.41 | Train f1: 0.13 | lr: 0.0009978919331864629\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 30/30 [02:45<00:00,  5.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.00003 | Val acc: 0.44 | Val f1: 0.14\n",
            "\n",
            "Saving model\n",
            "Epoch: 4/100 \n",
            "----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 226/226 [21:09<00:00,  5.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss  0.00003|Train acc : 0.47 | Train f1: 0.14 | lr: 0.000996254483124377\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 30/30 [02:45<00:00,  5.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.00003 | Val acc: 0.50 | Val f1: 0.15\n",
            "\n",
            "Saving model\n",
            "Epoch: 5/100 \n",
            "----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 226/226 [21:07<00:00,  5.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss  0.00003|Train acc : 0.52 | Train f1: 0.15 | lr: 0.0009941519617826901\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 30/30 [02:46<00:00,  5.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.00003 | Val acc: 0.55 | Val f1: 0.16\n",
            "\n",
            "Saving model\n",
            "Epoch: 6/100 \n",
            "----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 226/226 [21:14<00:00,  5.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss  0.00003|Train acc : 0.57 | Train f1: 0.16 | lr: 0.0009915864440961269\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 30/30 [02:45<00:00,  5.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.00003 | Val acc: 0.60 | Val f1: 0.17\n",
            "\n",
            "Saving model\n",
            "Epoch: 7/100 \n",
            "----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 226/226 [21:14<00:00,  5.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss  0.00003|Train acc : 0.62 | Train f1: 0.17 | lr: 0.0009885604619209046\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 30/30 [02:45<00:00,  5.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.00003 | Val acc: 0.64 | Val f1: 0.17\n",
            "\n",
            "Saving model\n",
            "Epoch: 8/100 \n",
            "----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 226/226 [21:11<00:00,  5.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss  0.00003|Train acc : 0.66 | Train f1: 0.18 | lr: 0.0009850770015360992\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 30/30 [02:48<00:00,  5.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.00003 | Val acc: 0.68 | Val f1: 0.18\n",
            "\n",
            "Saving model\n",
            "Epoch: 9/100 \n",
            "----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 226/226 [21:11<00:00,  5.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss  0.00003|Train acc : 0.70 | Train f1: 0.18 | lr: 0.0009811395006965474\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 30/30 [02:45<00:00,  5.51s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.00003 | Val acc: 0.72 | Val f1: 0.18\n",
            "\n",
            "Saving model\n",
            "Epoch: 10/100 \n",
            "----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 226/226 [21:12<00:00,  5.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss  0.00003|Train acc : 0.73 | Train f1: 0.18 | lr: 0.0009767518452401974\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 30/30 [02:45<00:00,  5.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.00003 | Val acc: 0.75 | Val f1: 0.18\n",
            "\n",
            "Saving model\n",
            "Epoch: 11/100 \n",
            "----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 226/226 [21:10<00:00,  5.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss  0.00003|Train acc : 0.76 | Train f1: 0.19 | lr: 0.0009719183652532566\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 30/30 [02:44<00:00,  5.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.00003 | Val acc: 0.78 | Val f1: 0.19\n",
            "\n",
            "Saving model\n",
            "Epoch: 12/100 \n",
            "----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 226/226 [21:10<00:00,  5.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss  0.00003|Train acc : 0.79 | Train f1: 0.19 | lr: 0.0009666438307969189\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 30/30 [02:45<00:00,  5.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.00002 | Val acc: 0.80 | Val f1: 0.19\n",
            "\n",
            "Saving model\n",
            "Epoch: 13/100 \n",
            "----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 226/226 [21:03<00:00,  5.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss  0.00002|Train acc : 0.81 | Train f1: 0.19 | lr: 0.0009609334471998905\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 30/30 [02:44<00:00,  5.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.00002 | Val acc: 0.82 | Val f1: 0.19\n",
            "\n",
            "Saving model\n",
            "Epoch: 14/100 \n",
            "----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 226/226 [21:05<00:00,  5.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss  0.00002|Train acc : 0.83 | Train f1: 0.19 | lr: 0.0009547928499213589\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 30/30 [02:45<00:00,  5.51s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.00002 | Val acc: 0.83 | Val f1: 0.19\n",
            "\n",
            "Saving model\n",
            "Epoch: 15/100 \n",
            "----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 226/226 [21:07<00:00,  5.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss  0.00002|Train acc : 0.84 | Train f1: 0.19 | lr: 0.0009482280989894743\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 30/30 [02:44<00:00,  5.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.00002 | Val acc: 0.85 | Val f1: 0.20\n",
            "\n",
            "Saving model\n",
            "Epoch: 16/100 \n",
            "----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 226/226 [21:04<00:00,  5.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss  0.00002|Train acc : 0.85 | Train f1: 0.20 | lr: 0.0009412456730208348\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 30/30 [02:35<00:00,  5.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.00002 | Val acc: 0.86 | Val f1: 0.20\n",
            "\n",
            "Saving model\n",
            "Epoch: 17/100 \n",
            "----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|      | 88/226 [08:00<12:43,  5.54s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uCQbmBuZjnNq"
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}